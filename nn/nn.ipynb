{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'imshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist-subset/0/16585.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m(img, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# display image as a greyscale\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\_api\\__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'imshow'"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"mnist-subset/0/16585.png\")\n",
    "plt.imshow(img, cmap=\"gray\") # display image as a greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classess = 10\n",
    "\n",
    "def img_to_vec(img):\n",
    "    \"\"\"Return a vector representation of an MNIST image file\"\"\"\n",
    "    img = Image.open(img)\n",
    "    return np.array(img)\n",
    "\n",
    "# D will house our data\n",
    "D = []\n",
    "\n",
    "# Iterate over all files that match the pattern \"mnist-subset/*/*.png\"\n",
    "# and add its information to `D`. We will sort the filenames so that we get\n",
    "# a consistent set of files in the training, validation, and test sets.\n",
    "for file in sorted(glob.glob(\"mnist-subset/*/*.png\")):\n",
    "    x = img_to_vec(file)   # vector input\n",
    "    t = file.split(os.sep)[1] # find out the target label by reading the file path\n",
    "    D.append((x, t),) # add this to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(D)\n",
    "D_train = D[:4000]     # the training set\n",
    "D_valid = D[4000:4500] # the validation set\n",
    "D_test  = D[4500:]     # the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack([x for (x, _) in D_train])\n",
    "t_train = np.eye(num_classess)[np.array([int(t) for (_, t) in D_train])]\n",
    "X_valid = np.stack([x for (x, _) in D_valid])\n",
    "t_valid = np.eye(num_classess)[np.array([int(t) for (_, t) in D_valid])]\n",
    "X_test = np.stack([x for (x, _) in D_test])\n",
    "t_test = np.eye(num_classess)[np.array([int(t) for (_, t) in D_test])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(1568, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.003377622691914439\n",
      "Epoch 2/50, Loss: 0.00018797008669935167\n",
      "Epoch 3/50, Loss: 0.015288724564015865\n",
      "Epoch 4/50, Loss: 0.00036186864599585533\n",
      "Epoch 5/50, Loss: 0.00043411817750893533\n",
      "Epoch 6/50, Loss: 0.0004009395488537848\n",
      "Epoch 7/50, Loss: 0.00010821464093169197\n",
      "Epoch 8/50, Loss: 2.433669760648627e-05\n",
      "Epoch 9/50, Loss: 3.043519200218725e-06\n",
      "Epoch 10/50, Loss: 2.5219901544915047e-06\n",
      "Epoch 11/50, Loss: 2.2761250875191763e-06\n",
      "Epoch 12/50, Loss: 2.019084604398813e-06\n",
      "Epoch 13/50, Loss: 1.750869159877766e-06\n",
      "Epoch 14/50, Loss: 1.5534319572907407e-06\n",
      "Epoch 15/50, Loss: 1.408147682013805e-06\n",
      "Epoch 16/50, Loss: 1.2628634067368694e-06\n",
      "Epoch 17/50, Loss: 1.110128891923523e-06\n",
      "Epoch 18/50, Loss: 1.0207227205683012e-06\n",
      "Epoch 19/50, Loss: 8.866141456564947e-07\n",
      "Epoch 20/50, Loss: 7.934828545330674e-07\n",
      "Epoch 21/50, Loss: 7.189776738414366e-07\n",
      "Epoch 22/50, Loss: 6.519229600598919e-07\n",
      "Epoch 23/50, Loss: 5.736926027566369e-07\n",
      "Epoch 24/50, Loss: 5.252639994068886e-07\n",
      "Epoch 25/50, Loss: 4.880114374827826e-07\n",
      "Epoch 26/50, Loss: 4.4703349999508646e-07\n",
      "Epoch 27/50, Loss: 4.172313197159383e-07\n",
      "Epoch 28/50, Loss: 3.762533822282421e-07\n",
      "Epoch 29/50, Loss: 3.427259684940509e-07\n",
      "Epoch 30/50, Loss: 3.3527535947541764e-07\n",
      "Epoch 31/50, Loss: 2.9802268386447395e-07\n",
      "Epoch 32/50, Loss: 2.6449518486515444e-07\n",
      "Epoch 33/50, Loss: 2.4959408051472565e-07\n",
      "Epoch 34/50, Loss: 2.2724239556737302e-07\n",
      "Epoch 35/50, Loss: 2.160665530936967e-07\n",
      "Epoch 36/50, Loss: 2.0116544874326792e-07\n",
      "Epoch 37/50, Loss: 1.937148681463441e-07\n",
      "Epoch 38/50, Loss: 1.8253902567266778e-07\n",
      "Epoch 39/50, Loss: 1.7136318319899146e-07\n",
      "Epoch 40/50, Loss: 1.6391263102377707e-07\n",
      "Epoch 41/50, Loss: 1.5273676012839132e-07\n",
      "Epoch 42/50, Loss: 1.4528620795317693e-07\n",
      "Epoch 43/50, Loss: 1.378356273562531e-07\n",
      "Epoch 44/50, Loss: 1.341103512686459e-07\n",
      "Epoch 45/50, Loss: 1.266597848825768e-07\n",
      "Epoch 46/50, Loss: 1.1920921139108032e-07\n",
      "Epoch 47/50, Loss: 1.1548392819804576e-07\n",
      "Epoch 48/50, Loss: 1.1175863789958385e-07\n",
      "Epoch 49/50, Loss: 1.0803335470654929e-07\n",
      "Epoch 50/50, Loss: 9.68574909165909e-08\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "from torch import float32\n",
    "\n",
    "learning_rate = 0.0008\n",
    "\n",
    "data = torch.tensor(X_train, dtype=float32).cuda()\n",
    "labels = torch.tensor(t_train, dtype=float32).cuda()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch_data = data[i:i+batch_size, None]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 97.40%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "valid = torch.tensor(X_valid[:, None, :, :], dtype=torch.float32).cuda()\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # Forward pass on validation data\n",
    "    outputs = model(valid)\n",
    "    \n",
    "    # Get predicted labels\n",
    "    _, predicted_val = torch.max(outputs, 1)\n",
    "    \n",
    "    results_val = predicted_val.detach().cpu().numpy()\n",
    "\n",
    "    # Convert one-hot encoded labels back to integers\n",
    "    t_valid_int = np.argmax(t_valid, axis=1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    correct_val = np.sum(results_val == t_valid_int)\n",
    "    accuracy_val = correct_val / len(t_valid_int)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_val * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test = torch.tensor(X_test[:, None, :, :], dtype=torch.float32).cuda()\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # Forward pass on testing data\n",
    "    outputs = model(test)\n",
    "    \n",
    "    # Get predicted labels\n",
    "    _, predicted_test = torch.max(outputs, 1)\n",
    "    \n",
    "    results_test = predicted_test.detach().cpu().numpy()\n",
    "\n",
    "    # Convert one-hot encoded labels back to integers\n",
    "    t_test_int = np.argmax(t_test, axis=1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    correct_test = np.sum(results_test == t_test_int)\n",
    "    accuracy_test = correct_test / len(t_test_int)\n",
    "\n",
    "print(f\"Testing Accuracy: {accuracy_test * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
